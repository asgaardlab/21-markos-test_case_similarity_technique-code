{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 1 for clustering similar test steps in natural language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Text embedding technique: Word2Vec\n",
    "* Text similarity: Word Mover's Distance (WMD)\n",
    "* Clustering techniques: Hierarchical agglomerative clustering and K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import gc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics as st\n",
    "import re\n",
    "import string\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For word frequency\n",
    "from collections import defaultdict\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.cluster.hierarchy as sch\n",
    "import gensim\n",
    "from gensim.models import Word2Vec, Phrases, KeyedVectors\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import RegexpTokenizer, word_tokenize, TweetTokenizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "\n",
    "# To be used with hierarchical clustering\n",
    "from joblib import Memory\n",
    "\n",
    "# To save models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download wordnet data through nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute number of unique words in df\n",
    "def get_number_unique_words(df):\n",
    "    words_list = list()\n",
    "    test_steps = list(df[\"Steps\"])\n",
    "    for step in test_steps:\n",
    "        for word in step:\n",
    "            words_list.append(word)\n",
    "    number_unique_words = len(set(words_list))\n",
    "    return number_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute number of unique words in df ('test case name' field)\n",
    "def get_number_unique_words_name(df):\n",
    "    words_list = list()\n",
    "    test_names = list(df[\"Case_Name\"])\n",
    "    for name in test_names:\n",
    "        for word in name:\n",
    "            words_list.append(word)\n",
    "    number_unique_words = len(set(words_list))\n",
    "    return number_unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get list of words that occur less than a certain number of times\n",
    "def get_word_frequency(df):\n",
    "    words_list = list()\n",
    "    test_steps = list(df[\"Steps\"])\n",
    "    for step in test_steps:\n",
    "        for word in step:\n",
    "            words_list.append(word)\n",
    "    unique_words_list = set(words_list)\n",
    "    word_occurrence_dict = {}\n",
    "    for each_word in unique_words_list:\n",
    "        word_occurrence_dict[each_word] = 0\n",
    "\n",
    "    for step in test_steps:\n",
    "        for word in step:\n",
    "            word_occurrence_dict[word] += 1\n",
    "            \n",
    "    ten_times_occurrence_words = list()\n",
    "    # get list of words that occur only once\n",
    "    for word, occurrence in word_occurrence_dict.items():\n",
    "        if occurrence < 2:\n",
    "            ten_times_occurrence_words.append(word)\n",
    "\n",
    "    return ten_times_occurrence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get list of words that occur less than a certain number of times ('test case name' field)\n",
    "def get_word_frequency_name(df):\n",
    "    words_list = list()\n",
    "    test_names = list(df[\"Case_Name\"])\n",
    "    for name in test_names:\n",
    "        for word in name:\n",
    "            words_list.append(word)\n",
    "    unique_words_list = set(words_list)\n",
    "    word_occurrence_dict = {}\n",
    "    for each_word in unique_words_list:\n",
    "        word_occurrence_dict[each_word] = 0\n",
    "\n",
    "    for name in test_names:\n",
    "        for word in name:\n",
    "            word_occurrence_dict[word] += 1\n",
    "            \n",
    "    ten_times_occurrence_words = list()\n",
    "    # get list of words that occur only once\n",
    "    for word, occurrence in word_occurrence_dict.items():\n",
    "        if occurrence < 2:\n",
    "            ten_times_occurrence_words.append(word)\n",
    "\n",
    "    return ten_times_occurrence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove problematic/mispelled words from vocabulary\n",
    "def remove_problematic_words(df):\n",
    "    number_unique_words = get_number_unique_words(df)\n",
    "    print(\"Number of unique words across all test steps: \", number_unique_words)\n",
    "    \n",
    "    # load file with problematic words that exist in the test data\n",
    "    problematic_words = open('word2vec_vocab_problematic.txt', 'r')\n",
    "    problematic_words_list = list()\n",
    "    for word in problematic_words:\n",
    "        problematic_words_list.append(word.lstrip().rstrip())\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        step = row[\"Steps\"]\n",
    "        df.loc[index][\"Steps\"] = [elem for elem in step if not elem in problematic_words_list]\n",
    "        \n",
    "    number_unique_words = get_number_unique_words(df)\n",
    "    print(\"Number of unique words across all test steps after removing problematic words: \", number_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to fix problematic/mispelled words from vocabulary\n",
    "def fix_problematic_words(df):\n",
    "    number_unique_words = get_number_unique_words(df)\n",
    "    print(\"Number of unique words across all test steps: \", number_unique_words)\n",
    "    \n",
    "    # load file with problematic words that exist in the test data\n",
    "    problematic_words = open('word2vec_vocab_to_fix.txt', 'r')\n",
    "    problematic_words_dict = {}\n",
    "    for line in problematic_words:\n",
    "        full_line = line.split(':')\n",
    "        try:\n",
    "            problematic_words_dict[full_line[0]] = [x.replace('\\n', '') for x in full_line[1].split(',')]\n",
    "        except:\n",
    "            problematic_words_dict[full_line[0]] = full_line[1].replace('\\n', '')\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        step = row[\"Steps\"]\n",
    "        modified_step = list()\n",
    "        for word in step:\n",
    "            if word in problematic_words_dict:\n",
    "                modified_step.extend(problematic_words_dict[word])\n",
    "            else:\n",
    "                modified_step.append(word)\n",
    "        df.loc[index][\"Steps\"] = modified_step \n",
    "        \n",
    "    number_unique_words = get_number_unique_words(df)\n",
    "    print(\"Number of unique words across all test steps after fixing problematic words: \", number_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_clean_data(df):\n",
    "    print(\"Cleaning test case name field...\")\n",
    "    print(\"Dataset size before preprocessing: \" , df.shape)\n",
    "    \n",
    "    # preprocessing and clean test name\n",
    "    \n",
    "    # replace url and similar structures (e.g, paths) with the keyword 'URL'\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: re.sub(r'http\\S+', 'URL', x))\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: re.sub('\\/[\\w-]*', '', x))\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: re.sub(r'\\{[^)]*\\}', '', x))\n",
    "    \n",
    "    # lowercase the step descriptions\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: x.lower())\n",
    "    \n",
    "    # remove digits and words with digits\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
    "    \n",
    "    # remove punctuations\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x))\n",
    "\n",
    "    # remove extra spaces\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: re.sub(' +',' ',x))\n",
    "\n",
    "    # tokenization\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: TweetTokenizer().tokenize(x))\n",
    "    number_unique_words = get_number_unique_words_name(df)\n",
    "    print(\"Number of unique words across all test names: \", number_unique_words)\n",
    "    \n",
    "    # stopword removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: [w for w in x if not w in stop_words])\n",
    "    number_unique_words = get_number_unique_words_name(df)\n",
    "    print(\"Number of unique words in test names after stopword removal: \", number_unique_words)\n",
    "    \n",
    "    # lemmatization\n",
    "    lemmatizer = WordNetLemmatizer() \n",
    "    df[\"Case_Name\"] = df[\"Case_Name\"].apply(lambda x: [lemmatizer.lemmatize(w) for w in x])\n",
    "    \n",
    "    # remove words that occur a certain number of times\n",
    "    ten_times_occurrence_words = get_word_frequency_name(df)\n",
    "    print(\"Number of words that occurred only once in test case names: \", len(ten_times_occurrence_words))\n",
    "    \n",
    "    # list of words to be removed\n",
    "    for index, row in df.iterrows():\n",
    "        current_test_name = row[\"Case_Name\"]\n",
    "        list_words_to_remove = list()\n",
    "        for word in current_test_name:\n",
    "            if word in ten_times_occurrence_words:\n",
    "                list_words_to_remove.append(word)\n",
    "        \n",
    "        df.loc[index][\"Case_Name\"] = [elem for elem in current_test_name if not elem in list_words_to_remove]\n",
    "\n",
    "#     # remove single letters present in the data\n",
    "#     df[\"Name\"] = df[\"Name\"].apply(lambda x: [w for w in x if len(w.strip()) > 1])\n",
    "\n",
    "    # remove instances with empty names\n",
    "    df = df.loc[df[\"Case_Name\"] != '']\n",
    "    \n",
    "    number_unique_words = get_number_unique_words_name(df)\n",
    "    print(\"Number of unique words in test names in the end: \", number_unique_words)\n",
    "    print(\"Dataset size after preprocessing: \" , df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and preprocess files with test cases and build dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data directory and list of xlsx files\n",
    "current_dir = os.getcwd() \n",
    "parent_dir = os.path.dirname(current_dir) + \"\\\\filtered_data\\\\\"\n",
    "xlsxfiles = [os.path.join(root, name)\n",
    "             for root, dirs, files in os.walk(parent_dir)\n",
    "             for name in files\n",
    "             if name.endswith((\".xlsx\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare pandas df to be populated\n",
    "column_names = [\"Type\", \"Key\", \"Case_Name\", \"Step_ID\", \"Steps\"]\n",
    "test_steps_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# Index to add data to the df\n",
    "index_to_add = 0\n",
    "\n",
    "print(\"Reading input data...\")   \n",
    "for test_file in xlsxfiles:\n",
    "    # load data and iterate through it\n",
    "    test_data_df = pd.read_excel(test_file)\n",
    "    for index, row in test_data_df.iterrows():\n",
    "        current_type = row[\"Type\"]\n",
    "        current_key = row[\"Key\"]\n",
    "        current_name = row[\"Case_Name\"]\n",
    "        current_step_id = row[\"Step_ID\"]\n",
    "        current_steps = row[\"Steps\"]\n",
    "        test_steps_df.loc[index_to_add] = [current_type, current_key, current_name, current_step_id, current_steps]\n",
    "        index_to_add += 1\n",
    "\n",
    "print(\"Done!\")\n",
    "print(\"Shape of data => \", test_steps_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call preprocessing function\n",
    "preprocess_clean_data(test_steps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess steps here as for some reason its not processing properly within the function\n",
    "# Replace urls with the keyword 'URL'\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: re.sub(r'http\\S+', 'URL', x))\n",
    "\n",
    "# Remove structures similar to urls (e.g, paths) \n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: re.sub('\\/[\\w-]*', '', x))\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: re.sub(r'\\{[^)]*\\}', '', x))\n",
    "\n",
    "# Lowercase the step descriptions\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: x.lower())\n",
    "\n",
    "# Remove digits and words with digits\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: re.sub('\\w*\\d\\w*','', x))\n",
    "\n",
    "# Remove punctuations\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), ' ', x))\n",
    "\n",
    "# Remove extra spaces\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: re.sub(' +',' ',x))\n",
    "\n",
    "# Tokenization\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: TweetTokenizer().tokenize(x))\n",
    "number_unique_words = get_number_unique_words(test_steps_df)\n",
    "print(\"Number of unique words across all test steps: \", number_unique_words)\n",
    "\n",
    "# Remove and fix mispelled words\n",
    "remove_problematic_words(test_steps_df)\n",
    "fix_problematic_words(test_steps_df)\n",
    "\n",
    "# Stopword removal\n",
    "stop_words = set(stopwords.words('english'))\n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: [w for w in x if not w in stop_words])\n",
    "number_unique_words = get_number_unique_words(test_steps_df)\n",
    "print(\"Number of unique words in test steps after stopword removal: \", number_unique_words)\n",
    "\n",
    "# Lemmatization\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "test_steps_df[\"Steps\"] = test_steps_df[\"Steps\"].apply(lambda x: [lemmatizer.lemmatize(w) for w in x])\n",
    "\n",
    "# Remove words that occur only once in all test fields\n",
    "ten_times_occurrence_words = get_word_frequency(test_steps_df)\n",
    "print(\"Number of words that occurred only once in test steps: \", len(ten_times_occurrence_words))\n",
    "\n",
    "for index, row in test_steps_df.iterrows():\n",
    "    current_test_step = row[\"Steps\"]\n",
    "    list_words_to_remove = list()\n",
    "    for word in current_test_step:\n",
    "        if word in ten_times_occurrence_words:\n",
    "            list_words_to_remove.append(word)\n",
    "\n",
    "    test_steps_df.loc[index][\"Steps\"] = [elem for elem in current_test_step if not elem in list_words_to_remove]\n",
    "\n",
    "number_unique_words = get_number_unique_words(test_steps_df)\n",
    "print(\"Number of unique words in test steps in the end: \", number_unique_words)\n",
    "print(\"Dataset size after preprocessing: \" , test_steps_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print head of preprocessed dataset\n",
    "test_steps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of list with training data:  15668\n"
     ]
    }
   ],
   "source": [
    "# Get only necessary fields to train word embedding models ('type', 'name', 'steps')\n",
    "# Note: 'type' is always a str, while 'name' and 'steps' are always lists (even if they have a single element)\n",
    "test_steps_training_list = list()\n",
    "for index, row in test_steps_df.iterrows():\n",
    "    temp_list = list()\n",
    "    if not pd.isnull(row[\"Type\"]):\n",
    "        temp_list.append(str(row[\"Type\"]))\n",
    "    \n",
    "    if isinstance(row[\"Case_Name\"], list):\n",
    "        for elem in row[\"Case_Name\"]:\n",
    "            temp_list.append(elem)\n",
    "    else:\n",
    "        if isinstance(row[\"Case_Name\"], str):\n",
    "            temp_list.append(row[\"Case_Name\"])\n",
    "\n",
    "    if isinstance(row[\"Steps\"], list):\n",
    "        for elem in row[\"Steps\"]:\n",
    "            temp_list.append(elem)\n",
    "    else:\n",
    "        if isinstance(row[\"Steps\"], str):\n",
    "            temp_list.append(row[\"Steps\"])\n",
    "            \n",
    "    # Build list of lists of tokens (words)\n",
    "    test_steps_training_list.append(temp_list)\n",
    "\n",
    "print(\"Length of list with training data: \" , len(test_steps_training_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all elements of the training data is correct (words should be strings)\n",
    "for step in test_steps_training_list:\n",
    "    for word in step:\n",
    "        if not isinstance(word, str):\n",
    "            print(\"Error with data type!\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute basic stats for the test steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of test steps\n",
    "print(\"Total number of steps : \", len(test_steps_training_list))\n",
    "\n",
    "# Average number of word per test step, name, and type together\n",
    "total_number_words_steps = sum([len(steps) for steps in test_steps_training_list])\n",
    "avg_words_per_step = total_number_words_steps/len(test_steps_training_list)\n",
    "print(\"Average number of words per test step: \", avg_words_per_step)\n",
    "\n",
    "# Most frequent words\n",
    "word_freq = defaultdict(int)\n",
    "for step in test_steps_training_list:\n",
    "    for word in step:\n",
    "        word_freq[str(word)] += 1\n",
    "sorted(word_freq, key=word_freq.get, reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train word embedding model - Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 2   # Minimum word count (this should hold for all existing words now - one-occurring words were already removed)                       \n",
    "num_workers = 4       # Number of threads to run in parallel (if necessary)\n",
    "context = 2         # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "my_model = Word2Vec(workers=num_workers,\n",
    "                   size=num_features,\n",
    "                   min_count = min_word_count,\n",
    "                   window = context,\n",
    "                   sample = downsampling)\n",
    "# default of sg=0 (CBOW) to match the default of the last version of word2vec.c from the original researchers\n",
    "\n",
    "my_model.build_vocab(test_steps_training_list)\n",
    "total_examples = my_model.corpus_count\n",
    "print(\"Size of initial vocabulary: \", len(my_model.wv.vocab.keys()))\n",
    "\n",
    "# Load pre-trained model (set your custom path to where the model is located)\n",
    "pre_trained_model_path = \"GoogleNews-vectors-negative300.bin\\\\GoogleNews-vectors-negative300.bin\"\n",
    "pre_trained_model = KeyedVectors.load_word2vec_format(pre_trained_model_path, binary=True)\n",
    "\n",
    "all_words = list(my_model.wv.vocab.keys())\n",
    "for each_word in all_words:\n",
    "    my_model.wv[each_word] = np.zeros(300)\n",
    "\n",
    "# Update vocabulary with our corpus (must set 'lockf' to 1.0 to update model vocabulary)\n",
    "my_model.build_vocab([list(pre_trained_model.vocab.keys())], update=True)\n",
    "my_model.intersect_word2vec_format(pre_trained_model_path, binary=True, lockf=1.0)\n",
    "\n",
    "# Get mean and sd of initialized word vectors\n",
    "word_vector_median_list = list()\n",
    "count_initiliazed = 0\n",
    "for each_word in all_words:\n",
    "    # if word vector was initialized\n",
    "    if any(my_model.wv[each_word] != 0):\n",
    "        word_vector_median_list.append(np.median(my_model.wv[each_word]))\n",
    "        count_initiliazed += 1\n",
    "print(\"Number of words already initialized : \" , count_initiliazed)\n",
    "\n",
    "# Define mean and sd for the normal distributions of medians        \n",
    "mu = np.mean(word_vector_median_list)\n",
    "sigma = np.std(word_vector_median_list)\n",
    "\n",
    "# Initialize the remaining word vectors (not present in the pre-trained model)\n",
    "count_manual_initiliazed = 0\n",
    "for each_word in all_words:\n",
    "    # if word vector was NOT initialized\n",
    "    if all(my_model.wv[each_word] == 0):\n",
    "        # initialize this word vector\n",
    "        new_word_vector = np.random.normal(mu, sigma, 300)\n",
    "        my_model.wv[each_word] = new_word_vector\n",
    "        count_manual_initiliazed += 1\n",
    "print(\"Number of words manually initialized : \" , count_manual_initiliazed)\n",
    "\n",
    "my_model.train(test_steps_training_list, total_examples=total_examples, epochs=15)\n",
    "end = time.time()\n",
    "print(f'Finished in {round(end-start,2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples of how we can use the trained model for word embedding\n",
    "print(my_model.predict_output_word(['launch', 'prodigy', 'select', 'device']), '\\n')\n",
    "print(my_model.wv.most_similar('epics'), '\\n')\n",
    "print(my_model.wv.doesnt_match(['wand', 'boot', 'house', 'weapon', 'hat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save vocab (uncomment to save the model vocabulary)\n",
    "# out_file= open(\"word2vec_vocab.txt\", \"a\")\n",
    "# for word in list(my_model.wv.vocab):\n",
    "#     out_file.write(word + '\\n')\n",
    "# out_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (uncomment to save)\n",
    "path_save_model = 'appr_1_my_model.model'\n",
    "# my_model.save(path_save_model)\n",
    "\n",
    "# Load the model (uncomment to load)\n",
    "path_load_model = 'appr_1_my_model.model'\n",
    "# my_model = Word2Vec.load(path_loadmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute distance (WMD) between all pairs of test steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tuples with (step_id, step_text) - used to retrieve the step ID in the end (after the clustering) - and get only test steps for clustering\n",
    "step_id_text_tuple_list = list()\n",
    "test_steps_clustering_list = list()\n",
    "for index, row in test_steps_df.iterrows():\n",
    "    step_id = row[\"Step_ID\"]\n",
    "    step_text = row[\"Steps\"]\n",
    "    step_id_text_tuple_list.append((step_id,step_text))\n",
    "\n",
    "    temp_list = list()\n",
    "    if isinstance(row[\"Steps\"], list):\n",
    "        for elem in row[\"Steps\"]:\n",
    "            temp_list.append(elem)\n",
    "    else:\n",
    "        if isinstance(row[\"Steps\"], str):\n",
    "            temp_list.append(row[\"Steps\"])\n",
    "        \n",
    "    # build list of lists of tokens (words)\n",
    "    test_steps_clustering_list.append(temp_list)\n",
    "    \n",
    "print(\"Length of list of tuples:\" , len(step_id_text_tuple_list))\n",
    "print(\"Length of list with test steps: \" , len(test_steps_clustering_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty steps\n",
    "index = 0\n",
    "steps_to_remove = list()\n",
    "for step in test_steps_clustering_list:\n",
    "    if len(step) == 0:\n",
    "        steps_to_remove.append(index)\n",
    "    index += 1\n",
    "\n",
    "step_id_text_tuple_list = [step_id_text_tuple_list[index] for index in range(len(step_id_text_tuple_list)) if not index in steps_to_remove]\n",
    "test_steps_clustering_list = [test_steps_clustering_list[index] for index in range(len(test_steps_clustering_list)) if not index in steps_to_remove]\n",
    "print(\"Length of list of tuples:\" , len(step_id_text_tuple_list))\n",
    "print(\"Length of list with test steps: \" , len(test_steps_clustering_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the number of test steps to rows and cols and initialize distance matrix with zeros\n",
    "rows = cols = len(test_steps_clustering_list)\n",
    "dist_matrix = np.zeros((rows, cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.perf_counter()\n",
    "print(\"Computing distances....\")\n",
    "for row in range(rows):\n",
    "    for col in range(row, cols):\n",
    "        computed_dist = my_model.wmdistance(test_steps_clustering_list[row], test_steps_clustering_list[col])\n",
    "        # Upper bound to avoid having inf values\n",
    "        if computed_dist > 1000:\n",
    "\t\t\tcomputed_dist = 1000\n",
    "        dist_matrix[row,col] = dist_matrix[col,row] = computed_dist\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'Finished in {round(finish-start,2)} second(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save distance matrix\n",
    "path_save_dist_matrix = 'appr_1_dist_matrix.txt'\n",
    "# np.savetxt(path_save_dist_matrix, dist_matrix)\n",
    "\n",
    "# load distance matrix\n",
    "path_load_dist_matrix = 'appr_1_dist_matrix.txt'\n",
    "dist_matrix = np.loadtxt(path_load_dist_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print matrix's shape and check if it's correct\n",
    "dist_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute hierarchical agglomerative clustering and K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the average word vector of a sentence (test step)\n",
    "def sent_avg_vector(sent, my_model, pre_trained_model):\n",
    "    list_word_vectors = list()\n",
    "    num_words = 0\n",
    "    for word in sent:\n",
    "        try:\n",
    "            list_word_vectors.append(my_model[word])\n",
    "        except:\n",
    "            try:\n",
    "                list_word_vectors.append(pre_trained_model[word])\n",
    "            except:\n",
    "                return np.zeros(300)\n",
    "        num_words += 1\n",
    "    sum_vectors = sum(list_word_vectors)\n",
    "    avg_vector = sum_vectors/num_words    \n",
    "    return avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute average word vector\n",
    "avg_word_sentence_vectors = list()\n",
    "for sentence in test_steps_clustering_list:\n",
    "    if len(sentence) > 0:\n",
    "        avg_word_sentence_vectors.append(sent_avg_vector(sentence, my_model, pre_trained_model))  \n",
    "print(\"========================\")\n",
    "print(\"Number of test steps: \" , len(avg_word_sentence_vectors))\n",
    "print(\"Dimension of one vector (should be 300 for word2vec)\" , len(avg_word_sentence_vectors[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ground truth of similar test steps (to compute F-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read excel files with ground truth of similar test steps (cannot be released due to sensitive information)\n",
    "ground_truth_dir = 'sample_manual_ground_truth/clusters/'\n",
    "sample_files = os.listdir(ground_truth_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_clusters_dict = {}\n",
    "for sample in sample_files:\n",
    "    sample_df = pd.read_excel(manual_sample_dir + sample)\n",
    "    for index, row in sample_df.iterrows():\n",
    "        cluster_id = row['cluster_id']\n",
    "        step_id = row['step_id']\n",
    "        if step_id in manual_clusters_dict:\n",
    "            existing_list = manual_clusters_dict[step_id]\n",
    "            existing_list.append(cluster_id)\n",
    "            manual_clusters_dict[step_id] = existing_list\n",
    "        else:\n",
    "            manual_clusters_dict[step_id] = [cluster_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test step samples which were manually clustered:  394\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test step samples which were manually clustered: \", len(manual_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps_to_evaluate_list = list(manual_clusters_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use F-score to tune number of clusters and evaluation\n",
    "aggl_model_list = list()\n",
    "kmeans_model_list = list()\n",
    "f_score_aggl_list = list()\n",
    "f_score_kmeans_list = list()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Iterate from 50 to 15,000 clusters\n",
    "for num_clusters in range(50, 15001, 50):\n",
    "    start = time.time()\n",
    "    print(\"Running for: \" + str(num_clusters) + \" clusters\")\n",
    "    aggl_clustering_model = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='average', memory=Memory('/tmp/memory_cache'))\n",
    "    aggl_clustering_model.fit(dist_matrix)\n",
    "    aggl_model_list.append(aggl_clustering_model)\n",
    "    labels = aggl_clustering_model.labels_\n",
    "    \n",
    "    # Compute f-score - declare and initialize variables to compute F-score\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    appr_clusters_dict = {}\n",
    "    for single_label in set(labels):\n",
    "        indices_label = np.where(labels == single_label)[0].tolist()\n",
    "        for ind in indices_label:\n",
    "            appr_clusters_dict[int(step_id_text_tuple_list[ind][0])] = single_label\n",
    "        \n",
    "    # Iterate through list of test steps to evaluate\n",
    "    for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "        for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "            step_id_1 = test_steps_to_evaluate_list[i]\n",
    "            step_id_2 = test_steps_to_evaluate_list[j]\n",
    "\n",
    "            # true positive case\n",
    "            if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "                TP += 1\n",
    "\n",
    "            # false positive case\n",
    "            elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "                FP += 1\n",
    "\n",
    "            # false negative case\n",
    "            elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "                FN += 1\n",
    "\n",
    "            # true negative case\n",
    "            elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "                TN += 1\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "    f_score_aggl_list.append(f_score)\n",
    "    \n",
    "    # Declare and initialize numpy ndarray for k means centroid initialization with shape: [n_clusters, n_features]\n",
    "    init_centroid_kmeans = np.zeros((num_clusters,300))\n",
    "\n",
    "    for single_label in set(labels):\n",
    "        indices_label = np.where(labels == single_label)[0].tolist()\n",
    "        sent_vectors_list = [avg_word_sentence_vectors[ind] for ind in indices_label]\n",
    "\n",
    "        # Compute average sentence vector between the selected sentences in 'sent_vectors_list'\n",
    "        avg_sent_vectors = sum(sent_vectors_list)/len(sent_vectors_list)\n",
    "        init_centroid_kmeans[single_label,:] = avg_sent_vectors    \n",
    "    \n",
    "    # Run K-Means with the computed centroids\n",
    "    kmeans = KMeans(n_clusters=num_clusters, init=init_centroid_kmeans, max_iter=300)\n",
    "    kmeans.fit(avg_word_sentence_vectors)\n",
    "    kmeans_model_list.append(kmeans)\n",
    "    labels = kmeans.labels_\n",
    "    \n",
    "    # Compute f-score - declare and initialize variables to compute F-score\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    appr_clusters_dict = {}\n",
    "    for single_label in set(labels):\n",
    "        indices_label = np.where(labels == single_label)[0].tolist()\n",
    "        for ind in indices_label:\n",
    "            appr_clusters_dict[int(step_id_text_tuple_list[ind][0])] = single_label\n",
    "        \n",
    "    # Tterate through list of steps to evaluate\n",
    "    for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "        for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "            step_id_1 = test_steps_to_evaluate_list[i]\n",
    "            step_id_2 = test_steps_to_evaluate_list[j]\n",
    "\n",
    "            # true positive case\n",
    "            if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "                TP += 1\n",
    "\n",
    "            # false positive case\n",
    "            elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "                FP += 1\n",
    "\n",
    "            # false negative case\n",
    "            elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "                FN += 1\n",
    "\n",
    "            # true negative case\n",
    "            elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "                TN += 1\n",
    "    \n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "    f_score_kmeans_list.append(f_score)    \n",
    "    \n",
    "    # Delete unnecessary variables to free memory up\n",
    "    del aggl_clustering_model\n",
    "    del kmeans\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f'Finished in {round(end-start,2)} second(s)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of hierarhical agglomerative clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot F-score against number of clusters\n",
    "plt.plot(list(range(50, 15001, 50)), f_score_aggl_list)\n",
    "plt.title('F-score - Agglomerative')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('F-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F-score:  0.8585086042065009\n",
      "Index of best F-score:  52\n"
     ]
    }
   ],
   "source": [
    "# Find max F-score and corresponding index\n",
    "max_score = max(f_score_aggl_list)\n",
    "max_index = f_score_aggl_list.index(max_score)\n",
    "print(\"Best F-score: \" , max_score)\n",
    "print(\"Index of best F-score: \", max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_aggl_model = aggl_model_list[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters of the best agglomerative model:  2650\n"
     ]
    }
   ],
   "source": [
    "# Get number of clusters of the best model\n",
    "best_aggl_model_num_clusters = best_aggl_model.n_clusters\n",
    "best_aggl_model_labels = best_aggl_model.labels_\n",
    "print(\"Number of clusters of the best agglomerative model: \", best_aggl_model_num_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clustered data\n",
    "path_to_save_data = \"appr_1_clustered_data.txt\"\n",
    "out_cluster_file = open(path_to_save_data, \"a\")\n",
    "for single_label in set(best_aggl_model_labels):\n",
    "    indices_label = np.where(best_aggl_model_labels == single_label)[0].tolist()\n",
    "    for index in indices_label:\n",
    "        str_to_save = \"[\" + str(single_label) + \"]:\\t\\t\" + test_steps_df.loc[index][\"Key\"] + \"\\t\\t\" + str(step_id_text_tuple_list[index][0]) + \"\\t\\t\"+ str(test_steps_clustering_list[index]) + \"\\n\"\n",
    "        out_cluster_file.write(str_to_save)\n",
    "out_cluster_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cluster labels (step IDs)\n",
    "path_to_save_labels = \"appr_1_cluster_labels.txt\"\n",
    "out_cluster_file = open(path_to_save_labels, \"a\")\n",
    "for single_label in set(best_aggl_model_labels):\n",
    "    indices_label = np.where(best_aggl_model_labels == single_label)[0].tolist()\n",
    "    str_to_save = \"[\" + str(single_label) + \"]: \" + ','.join(str(step_id_text_tuple_list[x][0]) for x in indices_label) + \"\\n\"\n",
    "    out_cluster_file.write(str_to_save)\n",
    "out_cluster_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of models and F-score\n",
    "model_index = 0\n",
    "aggl_models_path = \"results_approach_1/agglomerative_models/\"\n",
    "for aggl_model in aggl_model_list:\n",
    "    pickle.dump(aggl_model, open(aggl_models_path + \"agglomerative_model_\" + str(model_index) + \".pkl\", \"wb\"))\n",
    "    model_index += 1\n",
    "\n",
    "f_score_list_path = \"results_approach_1/appr_1_f_scores.txt\"\n",
    "np.savetxt(f_score_list_path, np.asarray(f_score_aggl_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of K-means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot F-score against number of clusters\n",
    "plt.plot(list(range(50, 15001, 50)), f_score_kmeans_list)\n",
    "plt.title('F-score - K-Means')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('F-score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F-score:  0.8698955365622032\n",
      "Index of best F-score:  52\n"
     ]
    }
   ],
   "source": [
    "# Find max F-score and corresponding index\n",
    "max_score = max(f_score_kmeans_list)\n",
    "max_index = f_score_kmeans_list.index(max_score)\n",
    "print(\"Best F-score: \" , max_score)\n",
    "print(\"Index of best F-score: \", max_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_kmeans_model = kmeans_model_list[max_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of clusters of the best k-means model:  2650\n",
      "Number of non-empty clusters of the best k-means model:  2650\n"
     ]
    }
   ],
   "source": [
    "# Get number of clusters of the best model\n",
    "best_kmeans_model_num_clusters = best_kmeans_model.n_clusters\n",
    "best_kmeans_model_labels = best_kmeans_model.labels_\n",
    "print(\"Number of clusters of the best k-means model: \", best_kmeans_model_num_clusters)\n",
    "print(\"Number of non-empty clusters of the best k-means model: \", len(set(best_kmeans_model.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save clustered data\n",
    "path_to_save_data = \"results_approach_1_kmeans/appr_1_kmeans_clustered_data.txt\"\n",
    "out_cluster_file = open(path_to_save_data, \"a\")\n",
    "for single_label in set(best_kmeans_model_labels):\n",
    "    indices_label = np.where(best_kmeans_model_labels == single_label)[0].tolist()\n",
    "    for index in indices_label:\n",
    "        str_to_save = \"[\" + str(single_label) + \"]:\\t\\t\" + test_steps_df.loc[index][\"Key\"] + \"\\t\\t\" + str(step_id_text_tuple_list[index][0]) + \"\\t\\t\"+ str(test_steps_clustering_list[index]) + \"\\n\"\n",
    "        out_cluster_file.write(str_to_save)\n",
    "out_cluster_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save cluster labels (step IDs)\n",
    "path_to_save_labels = \"appr_1_kmeans_cluster_labels.txt\"\n",
    "out_cluster_file = open(path_to_save_labels, \"a\")\n",
    "for single_label in set(best_kmeans_model_labels):\n",
    "    indices_label = np.where(best_kmeans_model_labels == single_label)[0].tolist()\n",
    "    str_to_save = \"[\" + str(single_label) + \"]: \" + ','.join(str(step_id_text_tuple_list[x][0]) for x in indices_label) + \"\\n\"\n",
    "    out_cluster_file.write(str_to_save)\n",
    "out_cluster_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save list of models and F-score\n",
    "model_index = 0\n",
    "kmeans_models_path = \"results_approach_1/kmeans_models/\"\n",
    "for kmeans_model in kmeans_model_list:\n",
    "    pickle.dump(kmeans_model, open(kmeans_models_path + \"kmeans_model_\" + str(model_index) + \".pkl\", \"wb\"))\n",
    "    model_index += 1\n",
    "\n",
    "f_score_list_path = \"results_approach_1/appr_1_kmeans_f_scores.txt\"\n",
    "np.savetxt(f_score_list_path, np.asarray(f_score_kmeans_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
