{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to evaluate all the clustering approaches using F-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load ground truth of similar test steps (to compute F-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read excel files with manually clustered samples\n",
    "manual_sample_dir = 'sample_manual_ground_truth/clusters/'\n",
    "sample_files = os.listdir(manual_sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_clusters_dict = {}\n",
    "for sample in sample_files:\n",
    "    sample_df = pd.read_excel(manual_sample_dir + sample)\n",
    "    for index, row in sample_df.iterrows():\n",
    "        cluster_id = row['cluster_id']\n",
    "        step_id = row['step_id']\n",
    "        if step_id in manual_clusters_dict:\n",
    "            existing_list = manual_clusters_dict[step_id]\n",
    "            existing_list.append(cluster_id)\n",
    "            manual_clusters_dict[step_id] = existing_list\n",
    "        else:\n",
    "            manual_clusters_dict[step_id] = [cluster_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test step samples which were manually clustered:  394\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test step samples which were manually clustered: \", len(manual_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_steps_to_evaluate_list = list(manual_clusters_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cluster_ids = list()\n",
    "for key in manual_clusters_dict:\n",
    "    list_cluster_ids.append(manual_clusters_dict[key][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {}\n",
    "for key in manual_clusters_dict:\n",
    "    clusterid = manual_clusters_dict[key][0]\n",
    "    if clusterid not in newdict:\n",
    "        cluster_dict[clusterid] = [key]\n",
    "    else:\n",
    "        existing_list = newdict[clusterid]\n",
    "        existing_list.append(key)\n",
    "        cluster_dict[clusterid] = existing_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of steps in clusters\n",
    "list_number_elements = list()\n",
    "for key in cluster_dict:\n",
    "    number_elements = len(cluster_dict[key])\n",
    "    list_number_elements.append(number_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                0\n",
      "count  213.000000\n",
      "mean     1.849765\n",
      "std      1.941591\n",
      "min      1.000000\n",
      "25%      1.000000\n",
      "50%      1.000000\n",
      "75%      2.000000\n",
      "max     15.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Plot distribution of steps in clusters (for the ground truth)\n",
    "plt.figure()\n",
    "pd.DataFrame(list_number_elements).plot.box()\n",
    "plt.title('Dist. similar test steps')\n",
    "plt.show()\n",
    "print(pd.DataFrame(list_number_elements).describe(), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory with experiment results\n",
    "experiment_results_dir = 'experiments/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 1 (hierarchical clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_1_dir = experiment_results_dir + 'results_approach_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_1_dir + 'appr_1_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9373695198329853\n",
      "Recall =  0.7918871252204586\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8585086042065009\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 1 (K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_1_kmeans_dir = experiment_results_dir + 'results_approach_1_kmeans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_1_kmeans_dir + 'appr_1_kmeans_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9423868312757202\n",
      "Recall =  0.8077601410934744\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8698955365622032\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 2 (hierarchical clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_2_dir = experiment_results_dir + 'results_approach_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_2_dir + 'appr_2_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.8956692913385826\n",
      "Recall =  0.8024691358024691\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8465116279069766\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 2 (K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_2_kmeans_dir = experiment_results_dir + 'results_approach_2_kmeans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_2_kmeans_dir + 'appr_2_kmeans_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9114688128772636\n",
      "Recall =  0.798941798941799\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8515037593984962\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 2 (hierarchical clustering) - Domain-adaptive pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_2_custom_dir = experiment_results_dir + 'results_approach_2_custom/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_2_custom_dir + 'appr_2_custom_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9389473684210526\n",
      "Recall =  0.7865961199294532\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8560460652591171\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 2 (K-means) - Domain-adaptive pre-trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_2_custom_kmeans_dir = experiment_results_dir + 'results_approach_2_custom_kmeans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_2_custom_kmeans_dir + 'appr_2_custom_kmeans_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9429175475687104\n",
      "Recall =  0.7865961199294532\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8576923076923076\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 3 (hierarchical clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_3_dir = experiment_results_dir + 'results_approach_3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_3_dir + 'appr_3_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9466950959488273\n",
      "Recall =  0.783068783068783\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.857142857142857\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 3 (K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_3_kmeans_dir = experiment_results_dir + 'results_approach_3_kmeans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_3_kmeans_dir + 'appr_3_kmeans_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9509594882729211\n",
      "Recall =  0.7865961199294532\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8610038610038611\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 4 (hierarchical clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_4_dir = experiment_results_dir + 'results_approach_4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_4_dir + 'appr_4_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9026369168356998\n",
      "Recall =  0.7848324514991182\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.839622641509434\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 4 (K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_4_kmeans_dir = experiment_results_dir + 'results_approach_4_kmeans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_4_kmeans_dir + 'appr_4_kmeans_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.8691588785046729\n",
      "Recall =  0.8201058201058201\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8439201451905626\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 5 (hierarhical clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_5_dir = experiment_results_dir + 'results_approach_5/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_5_dir + 'appr_5_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.9189723320158103\n",
      "Recall =  0.8201058201058201\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8667287977632805\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate approach 5 (K-means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_5_kmeans_dir = experiment_results_dir + 'results_approach_5_kmeans/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(approach_5_kmeans_dir + 'appr_5_kmeans_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  0.918\n",
      "Recall =  0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.8603561387066543\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Baseline 1 - Exact same steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_1_dir = experiment_results_dir + 'baseline_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(baseline_1_dir + 'baseline_1_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        # true positive case\n",
    "        if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            TP += 1\n",
    "            \n",
    "        # false positive case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "            FP += 1\n",
    "            \n",
    "        # false negative case\n",
    "        elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            FN += 1\n",
    "            \n",
    "        # true negative case\n",
    "        elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "            TN += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision =  1.0\n",
      "Recall =  0.5432098765432098\n"
     ]
    }
   ],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-score =  0.704\n"
     ]
    }
   ],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Baseline 2 - WMD = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_2_dir = experiment_results_dir + 'baseline_2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_clusters_dict = {}\n",
    "cluster_file = open(baseline_2_dir + 'baseline_2_cluster_labels.txt')\n",
    "for line in cluster_file:\n",
    "    full_line = line.split()\n",
    "    cluster_id = int(full_line[0].replace('[', '').replace(']', '').replace(':', ''))\n",
    "    step_id_list = full_line[1].split(',')\n",
    "    for step_id in step_id_list:\n",
    "        appr_clusters_dict[int(step_id)] = cluster_id\n",
    "cluster_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test steps which were clustered by the approach:  15644\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of test steps which were clustered by the approach: \", len(appr_clusters_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare and initialize variables to compute F-score\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through list of steps to evaluate\n",
    "for i in range(len(test_steps_to_evaluate_list)-1):\n",
    "    for j in range(i+1, len(test_steps_to_evaluate_list)):\n",
    "        step_id_1 = test_steps_to_evaluate_list[i]\n",
    "        step_id_2 = test_steps_to_evaluate_list[j]\n",
    "        \n",
    "        try:\n",
    "            # true positive case\n",
    "            if (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "                TP += 1\n",
    "\n",
    "            # false positive case\n",
    "            elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] == appr_clusters_dict[step_id_2]):\n",
    "                FP += 1\n",
    "\n",
    "            # false negative case\n",
    "            elif (manual_clusters_dict[step_id_1] == manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "                FN += 1\n",
    "\n",
    "            # true negative case\n",
    "            elif (manual_clusters_dict[step_id_1] != manual_clusters_dict[step_id_2]) and (appr_clusters_dict[step_id_1] != appr_clusters_dict[step_id_2]):\n",
    "                TN += 1\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = TP / (TP + FP)\n",
    "recall = TP / (TP + FN)\n",
    "print(\"Precision = \", precision)\n",
    "print(\"Recall = \", recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_score = (2 * precision * recall) / (precision + recall)\n",
    "print(\"F-score = \", f_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
